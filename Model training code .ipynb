{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T23:28:02.455770Z",
     "iopub.status.busy": "2025-08-22T23:28:02.455021Z",
     "iopub.status.idle": "2025-08-22T23:28:02.461715Z",
     "shell.execute_reply": "2025-08-22T23:28:02.460892Z",
     "shell.execute_reply.started": "2025-08-22T23:28:02.455750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os                          # To interact with the operating system\n",
    "import shutil                      # For file operations (copy, move, etc.)\n",
    "from io import BytesIO             # For byte operations\n",
    "\n",
    "# Numerical and data manipulation libraries\n",
    "import numpy as np                 # For numerical operations\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib.pyplot as plt     # For plotting graphs\n",
    "import seaborn as sns             # For data visualization\n",
    "\n",
    "# Image processing libraries\n",
    "from PIL import Image, ImageOps, ImageFile     # For image processing\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # For loading images\n",
    "\n",
    "# Audio analysis library\n",
    "import librosa                     # For audio analysis\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into train and test sets\n",
    "from sklearn.preprocessing import LabelEncoder  # For encoding labels\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing data\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # For evaluation metrics\n",
    "\n",
    "# TensorFlow/Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  # For creating sequential models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # For defining layers\n",
    "from tensorflow.keras.utils import to_categorical  # For converting labels to categorical format\n",
    "from tensorflow.keras.optimizers import Adam  # For optimization algorithms\n",
    "from tensorflow.keras.applications import MobileNet  # For pre-trained MobileNet model\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # For early stopping during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T23:28:08.232085Z",
     "iopub.status.busy": "2025-08-22T23:28:08.231817Z",
     "iopub.status.idle": "2025-08-22T23:28:08.235721Z",
     "shell.execute_reply": "2025-08-22T23:28:08.235180Z",
     "shell.execute_reply.started": "2025-08-22T23:28:08.232066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T23:28:08.827822Z",
     "iopub.status.busy": "2025-08-22T23:28:08.827591Z",
     "iopub.status.idle": "2025-08-22T23:37:04.835959Z",
     "shell.execute_reply": "2025-08-22T23:37:04.835412Z",
     "shell.execute_reply.started": "2025-08-22T23:28:08.827805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset'\n",
    "\n",
    "data = []   # List to store image arrays\n",
    "labels = []  # List to store corresponding labels for each image\n",
    "\n",
    "# Get a list of categories (subdirectories) in the dataset\n",
    "categories = os.listdir(data_path)\n",
    "\n",
    "# Loop through each category (i.e., each subdirectory)\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_path, category)  # Construct the full path to the category directory\n",
    "    \n",
    "    # Loop over each image in the current category\n",
    "    for img_name in os.listdir(category_path):\n",
    "        img_path = os.path.join(category_path, img_name)  # Construct the full path to the image file\n",
    "        \n",
    "        # Load and resize the image to (224, 224) pixels\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        \n",
    "        # Convert the image to a NumPy array\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # Normalize pixel values to the range [0, 1]\n",
    "        img_array /= 255.0\n",
    "        \n",
    "        # Append the processed image array to the data list\n",
    "        data.append(img_array)\n",
    "        \n",
    "        # Append the corresponding category label to the labels list\n",
    "        labels.append(category)\n",
    "\n",
    "# Encode the labels into numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert the encoded labels to a categorical format (one-hot encoding)\n",
    "categorical_labels = to_categorical(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T23:37:04.837418Z",
     "iopub.status.busy": "2025-08-22T23:37:04.837132Z",
     "iopub.status.idle": "2025-08-22T23:37:06.214551Z",
     "shell.execute_reply": "2025-08-22T23:37:06.213769Z",
     "shell.execute_reply.started": "2025-08-22T23:37:04.837390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (6284, 224, 224, 3)\n",
      "X_val shape is (786, 224, 224, 3)\n",
      "X_test shape is (786, 224, 224, 3)\n",
      "y_train shape is (6284, 31)\n",
      "y_val shape is (786, 31)\n",
      "y_test shape is (786, 31)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_label = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert the encoded labels to a categorical format (one-hot encoding)\n",
    "categorical_labels = to_categorical(encoded_label)\n",
    "\n",
    "# Split the dataset into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, categorical_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the test set into test and validation sets (50% each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert lists to NumPy arrays for easier processing in model training\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print the shapes of the datasets to confirm their dimensions\n",
    "print(f'X_train shape is {X_train.shape}')\n",
    "print(f'X_val shape is {X_val.shape}')\n",
    "print(f'X_test shape is {X_test.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')\n",
    "print(f'y_val shape is {y_val.shape}')\n",
    "print(f'y_test shape is {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T23:37:06.215770Z",
     "iopub.status.busy": "2025-08-22T23:37:06.215426Z",
     "iopub.status.idle": "2025-08-22T23:45:00.476464Z",
     "shell.execute_reply": "2025-08-22T23:45:00.475854Z",
     "shell.execute_reply.started": "2025-08-22T23:37:06.215745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755905831.673510      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1755905831.674180      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenet_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,775</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenet_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m3,228,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │        \u001b[38;5;34m31,775\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,260,639</span> (12.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,260,639\u001b[0m (12.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,775</span> (124.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,775\u001b[0m (124.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> (12.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,228,864\u001b[0m (12.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755905853.469331      98 service.cc:148] XLA service 0x7d5ca8126700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1755905853.470811      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1755905853.470831      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1755905854.117575      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/197\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.0677 - loss: 4.0611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755905859.155789      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1816 - loss: 3.0755\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62468, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 67ms/step - accuracy: 0.1822 - loss: 3.0726 - val_accuracy: 0.6247 - val_loss: 1.4420 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5598 - loss: 1.5062\n",
      "Epoch 2: val_accuracy improved from 0.62468 to 0.72392, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.5602 - loss: 1.5046 - val_accuracy: 0.7239 - val_loss: 1.0600 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m196/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6969 - loss: 1.0570\n",
      "Epoch 3: val_accuracy improved from 0.72392 to 0.74173, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.6969 - loss: 1.0567 - val_accuracy: 0.7417 - val_loss: 0.9204 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m196/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7300 - loss: 0.9018\n",
      "Epoch 4: val_accuracy improved from 0.74173 to 0.78626, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7301 - loss: 0.9015 - val_accuracy: 0.7863 - val_loss: 0.7844 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7800 - loss: 0.7567\n",
      "Epoch 5: val_accuracy did not improve from 0.78626\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7799 - loss: 0.7569 - val_accuracy: 0.7583 - val_loss: 0.7820 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7845 - loss: 0.6949\n",
      "Epoch 6: val_accuracy improved from 0.78626 to 0.79135, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7845 - loss: 0.6949 - val_accuracy: 0.7913 - val_loss: 0.6976 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8347 - loss: 0.5960\n",
      "Epoch 7: val_accuracy improved from 0.79135 to 0.80025, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8344 - loss: 0.5962 - val_accuracy: 0.8003 - val_loss: 0.6897 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8404 - loss: 0.5531\n",
      "Epoch 8: val_accuracy did not improve from 0.80025\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8403 - loss: 0.5533 - val_accuracy: 0.7952 - val_loss: 0.6837 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8508 - loss: 0.5275\n",
      "Epoch 9: val_accuracy did not improve from 0.80025\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8507 - loss: 0.5277 - val_accuracy: 0.7888 - val_loss: 0.6859 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8466 - loss: 0.4991\n",
      "Epoch 10: val_accuracy did not improve from 0.80025\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8466 - loss: 0.4993 - val_accuracy: 0.7952 - val_loss: 0.6543 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8673 - loss: 0.4551\n",
      "Epoch 11: val_accuracy improved from 0.80025 to 0.80789, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.8671 - loss: 0.4554 - val_accuracy: 0.8079 - val_loss: 0.6193 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8638 - loss: 0.4498\n",
      "Epoch 12: val_accuracy did not improve from 0.80789\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8638 - loss: 0.4499 - val_accuracy: 0.7964 - val_loss: 0.6384 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8762 - loss: 0.4271\n",
      "Epoch 13: val_accuracy improved from 0.80789 to 0.81552, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.8761 - loss: 0.4272 - val_accuracy: 0.8155 - val_loss: 0.6026 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8804 - loss: 0.4041\n",
      "Epoch 14: val_accuracy did not improve from 0.81552\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8804 - loss: 0.4043 - val_accuracy: 0.8092 - val_loss: 0.6212 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8813 - loss: 0.3935\n",
      "Epoch 15: val_accuracy did not improve from 0.81552\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8812 - loss: 0.3936 - val_accuracy: 0.8104 - val_loss: 0.6162 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8921 - loss: 0.3494\n",
      "Epoch 16: val_accuracy did not improve from 0.81552\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.8921 - loss: 0.3495 - val_accuracy: 0.8066 - val_loss: 0.6081 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8978 - loss: 0.3674\n",
      "Epoch 17: val_accuracy improved from 0.81552 to 0.81679, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.8978 - loss: 0.3673 - val_accuracy: 0.8168 - val_loss: 0.5922 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8922 - loss: 0.3636\n",
      "Epoch 18: val_accuracy did not improve from 0.81679\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.8923 - loss: 0.3635 - val_accuracy: 0.8053 - val_loss: 0.6142 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9007 - loss: 0.3372\n",
      "Epoch 19: val_accuracy did not improve from 0.81679\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.9007 - loss: 0.3374 - val_accuracy: 0.8079 - val_loss: 0.5867 - learning_rate: 5.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8934 - loss: 0.3535\n",
      "Epoch 20: val_accuracy improved from 0.81679 to 0.82061, saving model to /kaggle/working/best_stage1.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.8933 - loss: 0.3535 - val_accuracy: 0.8206 - val_loss: 0.5795 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8999 - loss: 0.3406\n",
      "Epoch 21: val_accuracy did not improve from 0.82061\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8999 - loss: 0.3405 - val_accuracy: 0.8053 - val_loss: 0.6086 - learning_rate: 5.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9014 - loss: 0.3226\n",
      "Epoch 22: val_accuracy did not improve from 0.82061\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.9014 - loss: 0.3227 - val_accuracy: 0.8117 - val_loss: 0.5969 - learning_rate: 5.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9099 - loss: 0.3157\n",
      "Epoch 23: val_accuracy did not improve from 0.82061\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.9099 - loss: 0.3157 - val_accuracy: 0.8117 - val_loss: 0.5827 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m195/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9152 - loss: 0.3096\n",
      "Epoch 24: val_accuracy did not improve from 0.82061\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.9152 - loss: 0.3097 - val_accuracy: 0.8092 - val_loss: 0.5858 - learning_rate: 2.5000e-04\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "Epoch 1/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6245 - loss: 1.4256\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69466, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - accuracy: 0.6247 - loss: 1.4244 - val_accuracy: 0.6947 - val_loss: 1.1210 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7831 - loss: 0.6756\n",
      "Epoch 2: val_accuracy improved from 0.69466 to 0.76463, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.7831 - loss: 0.6755 - val_accuracy: 0.7646 - val_loss: 0.7904 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8249 - loss: 0.5242\n",
      "Epoch 3: val_accuracy improved from 0.76463 to 0.80789, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.8249 - loss: 0.5240 - val_accuracy: 0.8079 - val_loss: 0.6306 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8527 - loss: 0.4374\n",
      "Epoch 4: val_accuracy improved from 0.80789 to 0.81425, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.8527 - loss: 0.4373 - val_accuracy: 0.8142 - val_loss: 0.5785 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8824 - loss: 0.3357\n",
      "Epoch 5: val_accuracy improved from 0.81425 to 0.83206, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.8824 - loss: 0.3357 - val_accuracy: 0.8321 - val_loss: 0.5253 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8863 - loss: 0.3275\n",
      "Epoch 6: val_accuracy improved from 0.83206 to 0.83461, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.8863 - loss: 0.3274 - val_accuracy: 0.8346 - val_loss: 0.5096 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9061 - loss: 0.2869\n",
      "Epoch 7: val_accuracy improved from 0.83461 to 0.83969, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9061 - loss: 0.2869 - val_accuracy: 0.8397 - val_loss: 0.4851 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9176 - loss: 0.2402\n",
      "Epoch 8: val_accuracy improved from 0.83969 to 0.84987, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9176 - loss: 0.2402 - val_accuracy: 0.8499 - val_loss: 0.4604 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9299 - loss: 0.2069\n",
      "Epoch 9: val_accuracy improved from 0.84987 to 0.85369, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9299 - loss: 0.2069 - val_accuracy: 0.8537 - val_loss: 0.4388 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9323 - loss: 0.1973\n",
      "Epoch 10: val_accuracy improved from 0.85369 to 0.85751, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9323 - loss: 0.1973 - val_accuracy: 0.8575 - val_loss: 0.4210 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9419 - loss: 0.1736\n",
      "Epoch 11: val_accuracy improved from 0.85751 to 0.86387, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9419 - loss: 0.1736 - val_accuracy: 0.8639 - val_loss: 0.4139 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9429 - loss: 0.1645\n",
      "Epoch 12: val_accuracy improved from 0.86387 to 0.86641, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9429 - loss: 0.1645 - val_accuracy: 0.8664 - val_loss: 0.4085 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9462 - loss: 0.1517\n",
      "Epoch 13: val_accuracy improved from 0.86641 to 0.87659, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9462 - loss: 0.1516 - val_accuracy: 0.8766 - val_loss: 0.3916 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9610 - loss: 0.1222\n",
      "Epoch 14: val_accuracy did not improve from 0.87659\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9610 - loss: 0.1222 - val_accuracy: 0.8753 - val_loss: 0.3802 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9599 - loss: 0.1169\n",
      "Epoch 15: val_accuracy improved from 0.87659 to 0.88295, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9599 - loss: 0.1169 - val_accuracy: 0.8830 - val_loss: 0.3744 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9628 - loss: 0.1143\n",
      "Epoch 16: val_accuracy did not improve from 0.88295\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9628 - loss: 0.1142 - val_accuracy: 0.8817 - val_loss: 0.3703 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9689 - loss: 0.0996\n",
      "Epoch 17: val_accuracy did not improve from 0.88295\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9689 - loss: 0.0996 - val_accuracy: 0.8830 - val_loss: 0.3629 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9686 - loss: 0.0924\n",
      "Epoch 18: val_accuracy did not improve from 0.88295\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9686 - loss: 0.0924 - val_accuracy: 0.8804 - val_loss: 0.3621 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9761 - loss: 0.0828\n",
      "Epoch 19: val_accuracy did not improve from 0.88295\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9761 - loss: 0.0828 - val_accuracy: 0.8804 - val_loss: 0.3533 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9740 - loss: 0.0815\n",
      "Epoch 20: val_accuracy improved from 0.88295 to 0.88931, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9740 - loss: 0.0815 - val_accuracy: 0.8893 - val_loss: 0.3463 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9762 - loss: 0.0690\n",
      "Epoch 21: val_accuracy improved from 0.88931 to 0.89186, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9762 - loss: 0.0690 - val_accuracy: 0.8919 - val_loss: 0.3453 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9834 - loss: 0.0561\n",
      "Epoch 22: val_accuracy improved from 0.89186 to 0.89313, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9834 - loss: 0.0561 - val_accuracy: 0.8931 - val_loss: 0.3350 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9828 - loss: 0.0621\n",
      "Epoch 23: val_accuracy did not improve from 0.89313\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9828 - loss: 0.0621 - val_accuracy: 0.8931 - val_loss: 0.3334 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0616\n",
      "Epoch 24: val_accuracy did not improve from 0.89313\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9836 - loss: 0.0616 - val_accuracy: 0.8919 - val_loss: 0.3293 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9856 - loss: 0.0524\n",
      "Epoch 25: val_accuracy improved from 0.89313 to 0.89440, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9855 - loss: 0.0525 - val_accuracy: 0.8944 - val_loss: 0.3289 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9864 - loss: 0.0505\n",
      "Epoch 26: val_accuracy did not improve from 0.89440\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9864 - loss: 0.0505 - val_accuracy: 0.8944 - val_loss: 0.3250 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9872 - loss: 0.0452\n",
      "Epoch 27: val_accuracy did not improve from 0.89440\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9872 - loss: 0.0452 - val_accuracy: 0.8931 - val_loss: 0.3246 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9927 - loss: 0.0401\n",
      "Epoch 28: val_accuracy improved from 0.89440 to 0.90331, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9927 - loss: 0.0401 - val_accuracy: 0.9033 - val_loss: 0.3167 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9874 - loss: 0.0397\n",
      "Epoch 29: val_accuracy did not improve from 0.90331\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9874 - loss: 0.0397 - val_accuracy: 0.9008 - val_loss: 0.3179 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0447\n",
      "Epoch 30: val_accuracy improved from 0.90331 to 0.90458, saving model to /kaggle/working/best_finetuned.h5\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9865 - loss: 0.0446 - val_accuracy: 0.9046 - val_loss: 0.3128 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Saved model to: /kaggle/working/mobilenet_finetuned.h5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8846 - loss: 0.3854\n",
      "Test loss: 0.3207  Test accuracy: 0.8982\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step\n",
      "\n",
      "Classification report (per-class):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    1.0000    0.9474        27\n",
      "           1     0.8571    1.0000    0.9231        18\n",
      "           2     1.0000    1.0000    1.0000        29\n",
      "           3     0.8378    0.9394    0.8857        33\n",
      "           4     0.9231    0.8889    0.9057        27\n",
      "           5     0.7200    0.9000    0.8000        20\n",
      "           6     0.8571    0.9000    0.8780        20\n",
      "           7     0.9524    1.0000    0.9756        20\n",
      "           8     0.9333    0.7778    0.8485        18\n",
      "           9     0.8519    0.9583    0.9020        24\n",
      "          10     0.9565    0.9167    0.9362        24\n",
      "          11     0.8788    0.9355    0.9062        31\n",
      "          12     0.9615    0.8929    0.9259        28\n",
      "          13     0.8800    0.9565    0.9167        23\n",
      "          14     1.0000    0.7407    0.8511        27\n",
      "          15     0.8636    0.7600    0.8085        25\n",
      "          16     0.9118    0.9118    0.9118        34\n",
      "          17     0.9412    0.7273    0.8205        22\n",
      "          18     0.9444    0.7727    0.8500        22\n",
      "          19     0.9032    0.9333    0.9180        30\n",
      "          20     0.9500    0.9500    0.9500        20\n",
      "          21     1.0000    0.9697    0.9846        33\n",
      "          22     0.8824    0.8824    0.8824        17\n",
      "          23     0.9231    0.8571    0.8889        42\n",
      "          24     0.9545    0.9545    0.9545        22\n",
      "          25     0.6538    0.8947    0.7556        19\n",
      "          26     0.8519    0.7931    0.8214        29\n",
      "          27     1.0000    1.0000    1.0000        24\n",
      "          28     0.8000    0.9333    0.8615        30\n",
      "          29     0.8696    0.9091    0.8889        22\n",
      "          30     1.0000    0.7692    0.8696        26\n",
      "\n",
      "    accuracy                         0.8982       786\n",
      "   macro avg     0.9019    0.8976    0.8957       786\n",
      "weighted avg     0.9055    0.8982    0.8981       786\n",
      "\n",
      "Confusion matrix shape: (31, 31)\n"
     ]
    }
   ],
   "source": [
    "#  Model building + training (uses your X_train, X_val, X_test, y_train, y_val, y_test) \n",
    "import os, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNet  # you imported MobileNet earlier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --------- Config ----------\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 32            # reduce to 16 or 8 if you get OOM\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "OUT_DIR = \"/kaggle/working\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "SEED = 42\n",
    "\n",
    "# --------- Ensure arrays are float32 and labels are float32 as well ----------\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_val   = X_val.astype(\"float32\")\n",
    "X_test  = X_test.astype(\"float32\")\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_val   = y_val.astype(\"float32\")\n",
    "y_test  = y_test.astype(\"float32\")\n",
    "\n",
    "# --------- Build tf.data pipelines from numpy arrays (fast + supports prefetch/AUTOTUNE) ----------\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.shuffle(buffer_size=len(X_train), seed=SEED).batch(BATCH).prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH).prefetch(AUTOTUNE)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH).prefetch(AUTOTUNE)\n",
    "\n",
    "# --------- Build model: MobileNet backbone (pretrained) + head ----------\n",
    "NUM_CLASSES = y_train.shape[1]  # should be 31 in your dataset\n",
    "\n",
    "# load MobileNet (pretrained on ImageNet) without top classifier\n",
    "base_model = MobileNet(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "base_model.trainable = False   # STAGE 1: freeze backbone (feature extraction)\n",
    "\n",
    "# build classification head\n",
    "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "x = base_model(inputs, training=False)            # keep base in inference mode\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# compile for stage 1\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --------- Callbacks ----------\n",
    "ckpt1 = ModelCheckpoint(os.path.join(OUT_DIR, \"best_stage1.h5\"),\n",
    "                        save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1)\n",
    "es1 = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True, verbose=1)\n",
    "rlp = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "# --------- STAGE 1: train head only (feature extraction) ----------\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,                # enough for head; early stopping will cut if needed\n",
    "    callbacks=[ckpt1, es1, rlp],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ensure best weights loaded\n",
    "if os.path.exists(os.path.join(OUT_DIR, \"best_stage1.h5\")):\n",
    "    model.load_weights(os.path.join(OUT_DIR, \"best_stage1.h5\"))\n",
    "\n",
    "# --------- STAGE 2: fine-tune top layers of the backbone ----------\n",
    "# unfreeze backbone\n",
    "base_model.trainable = True\n",
    "\n",
    "# freeze lower layers, fine-tune top ~30% (adjustable)\n",
    "fine_tune_at = int(len(base_model.layers) * 0.7)\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# recompile with a much lower LR for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "ckpt2 = ModelCheckpoint(os.path.join(OUT_DIR, \"best_finetuned.h5\"),\n",
    "                        save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1)\n",
    "es2 = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,             # small number, fine-tuning doesn't need many epochs\n",
    "    callbacks=[ckpt2, es2, rlp],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# load best fine-tuned weights\n",
    "if os.path.exists(os.path.join(OUT_DIR, \"best_finetuned.h5\")):\n",
    "    model.load_weights(os.path.join(OUT_DIR, \"best_finetuned.h5\"))\n",
    "\n",
    "# --------- Save final model ----------\n",
    "final_model_path = os.path.join(OUT_DIR, \"mobilenet_finetuned.h5\")\n",
    "model.save(final_model_path)\n",
    "print(\"Saved model to:\", final_model_path)\n",
    "\n",
    "# --------- Evaluate on test set and show classification report ----------\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"Test loss: {test_loss:.4f}  Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# get predictions and printable report\n",
    "y_pred = model.predict(test_ds)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)   # y_test is numpy array of one-hot\n",
    "\n",
    "print(\"\\nClassification report (per-class):\")\n",
    "print(classification_report(y_true_labels, y_pred_labels, digits=4))\n",
    "\n",
    "# Confusion matrix (optional - can be large)\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "print(\"Confusion matrix shape:\", cm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
    "17225924/17225924 ━━━━━━━━━━━━━━━━━━━━ 0s 0us/step\n",
    "Model: \"functional\"\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ input_layer_1 (InputLayer)      │ (None, 224, 224, 3)    │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ mobilenet_1.00_224 (Functional) │ (None, 7, 7, 1024)     │     3,228,864 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ global_average_pooling2d        │ (None, 1024)           │             0 │\n",
    "│ (GlobalAveragePooling2D)        │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None, 1024)           │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense (Dense)                   │ (None, 31)             │        31,775 │\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    " Total params: 3,260,639 (12.44 MB)\n",
    " Trainable params: 31,775 (124.12 KB)\n",
    " Non-trainable params: 3,228,864 (12.32 MB)\n",
    "Epoch 1/30\n",
    "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
    "I0000 00:00:1755905853.469331      98 service.cc:148] XLA service 0x7d5ca8126700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    "I0000 00:00:1755905853.470811      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
    "I0000 00:00:1755905853.470831      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
    "I0000 00:00:1755905854.117575      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
    "  7/197 ━━━━━━━━━━━━━━━━━━━━ 5s 27ms/step - accuracy: 0.0677 - loss: 4.0611\n",
    "I0000 00:00:1755905859.155789      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.1816 - loss: 3.0755\n",
    "Epoch 1: val_accuracy improved from -inf to 0.62468, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 26s 67ms/step - accuracy: 0.1822 - loss: 3.0726 - val_accuracy: 0.6247 - val_loss: 1.4420 - learning_rate: 0.0010\n",
    "Epoch 2/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.5598 - loss: 1.5062\n",
    "Epoch 2: val_accuracy improved from 0.62468 to 0.72392, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.5602 - loss: 1.5046 - val_accuracy: 0.7239 - val_loss: 1.0600 - learning_rate: 0.0010\n",
    "Epoch 3/30\n",
    "196/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.6969 - loss: 1.0570\n",
    "Epoch 3: val_accuracy improved from 0.72392 to 0.74173, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.6969 - loss: 1.0567 - val_accuracy: 0.7417 - val_loss: 0.9204 - learning_rate: 0.0010\n",
    "Epoch 4/30\n",
    "196/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.7300 - loss: 0.9018\n",
    "Epoch 4: val_accuracy improved from 0.74173 to 0.78626, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.7301 - loss: 0.9015 - val_accuracy: 0.7863 - val_loss: 0.7844 - learning_rate: 0.0010\n",
    "Epoch 5/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.7800 - loss: 0.7567\n",
    "Epoch 5: val_accuracy did not improve from 0.78626\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 29ms/step - accuracy: 0.7799 - loss: 0.7569 - val_accuracy: 0.7583 - val_loss: 0.7820 - learning_rate: 0.0010\n",
    "Epoch 6/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.7845 - loss: 0.6949\n",
    "Epoch 6: val_accuracy improved from 0.78626 to 0.79135, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.7845 - loss: 0.6949 - val_accuracy: 0.7913 - val_loss: 0.6976 - learning_rate: 0.0010\n",
    "Epoch 7/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.8347 - loss: 0.5960\n",
    "Epoch 7: val_accuracy improved from 0.79135 to 0.80025, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8344 - loss: 0.5962 - val_accuracy: 0.8003 - val_loss: 0.6897 - learning_rate: 0.0010\n",
    "Epoch 8/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8404 - loss: 0.5531\n",
    "Epoch 8: val_accuracy did not improve from 0.80025\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8403 - loss: 0.5533 - val_accuracy: 0.7952 - val_loss: 0.6837 - learning_rate: 0.0010\n",
    "Epoch 9/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8508 - loss: 0.5275\n",
    "Epoch 9: val_accuracy did not improve from 0.80025\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8507 - loss: 0.5277 - val_accuracy: 0.7888 - val_loss: 0.6859 - learning_rate: 0.0010\n",
    "Epoch 10/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8466 - loss: 0.4991\n",
    "Epoch 10: val_accuracy did not improve from 0.80025\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8466 - loss: 0.4993 - val_accuracy: 0.7952 - val_loss: 0.6543 - learning_rate: 0.0010\n",
    "Epoch 11/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.8673 - loss: 0.4551\n",
    "Epoch 11: val_accuracy improved from 0.80025 to 0.80789, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.8671 - loss: 0.4554 - val_accuracy: 0.8079 - val_loss: 0.6193 - learning_rate: 0.0010\n",
    "Epoch 12/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8638 - loss: 0.4498\n",
    "Epoch 12: val_accuracy did not improve from 0.80789\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8638 - loss: 0.4499 - val_accuracy: 0.7964 - val_loss: 0.6384 - learning_rate: 0.0010\n",
    "Epoch 13/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8762 - loss: 0.4271\n",
    "Epoch 13: val_accuracy improved from 0.80789 to 0.81552, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.8761 - loss: 0.4272 - val_accuracy: 0.8155 - val_loss: 0.6026 - learning_rate: 0.0010\n",
    "Epoch 14/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8804 - loss: 0.4041\n",
    "Epoch 14: val_accuracy did not improve from 0.81552\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8804 - loss: 0.4043 - val_accuracy: 0.8092 - val_loss: 0.6212 - learning_rate: 0.0010\n",
    "Epoch 15/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8813 - loss: 0.3935\n",
    "Epoch 15: val_accuracy did not improve from 0.81552\n",
    "\n",
    "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8812 - loss: 0.3936 - val_accuracy: 0.8104 - val_loss: 0.6162 - learning_rate: 0.0010\n",
    "Epoch 16/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8921 - loss: 0.3494\n",
    "Epoch 16: val_accuracy did not improve from 0.81552\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.8921 - loss: 0.3495 - val_accuracy: 0.8066 - val_loss: 0.6081 - learning_rate: 5.0000e-04\n",
    "Epoch 17/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.8978 - loss: 0.3674\n",
    "Epoch 17: val_accuracy improved from 0.81552 to 0.81679, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 32ms/step - accuracy: 0.8978 - loss: 0.3673 - val_accuracy: 0.8168 - val_loss: 0.5922 - learning_rate: 5.0000e-04\n",
    "Epoch 18/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8922 - loss: 0.3636\n",
    "Epoch 18: val_accuracy did not improve from 0.81679\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.8923 - loss: 0.3635 - val_accuracy: 0.8053 - val_loss: 0.6142 - learning_rate: 5.0000e-04\n",
    "Epoch 19/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9007 - loss: 0.3372\n",
    "Epoch 19: val_accuracy did not improve from 0.81679\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.9007 - loss: 0.3374 - val_accuracy: 0.8079 - val_loss: 0.5867 - learning_rate: 5.0000e-04\n",
    "Epoch 20/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8934 - loss: 0.3535\n",
    "Epoch 20: val_accuracy improved from 0.81679 to 0.82061, saving model to /kaggle/working/best_stage1.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.8933 - loss: 0.3535 - val_accuracy: 0.8206 - val_loss: 0.5795 - learning_rate: 5.0000e-04\n",
    "Epoch 21/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.8999 - loss: 0.3406\n",
    "Epoch 21: val_accuracy did not improve from 0.82061\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.8999 - loss: 0.3405 - val_accuracy: 0.8053 - val_loss: 0.6086 - learning_rate: 5.0000e-04\n",
    "Epoch 22/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.9014 - loss: 0.3226\n",
    "Epoch 22: val_accuracy did not improve from 0.82061\n",
    "\n",
    "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.9014 - loss: 0.3227 - val_accuracy: 0.8117 - val_loss: 0.5969 - learning_rate: 5.0000e-04\n",
    "Epoch 23/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.9099 - loss: 0.3157\n",
    "Epoch 23: val_accuracy did not improve from 0.82061\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 30ms/step - accuracy: 0.9099 - loss: 0.3157 - val_accuracy: 0.8117 - val_loss: 0.5827 - learning_rate: 2.5000e-04\n",
    "Epoch 24/30\n",
    "195/197 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.9152 - loss: 0.3096\n",
    "Epoch 24: val_accuracy did not improve from 0.82061\n",
    "\n",
    "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 6s 31ms/step - accuracy: 0.9152 - loss: 0.3097 - val_accuracy: 0.8092 - val_loss: 0.5858 - learning_rate: 2.5000e-04\n",
    "Epoch 24: early stopping\n",
    "Restoring model weights from the end of the best epoch: 20.\n",
    "Epoch 1/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6245 - loss: 1.4256\n",
    "Epoch 1: val_accuracy improved from -inf to 0.69466, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 28s 79ms/step - accuracy: 0.6247 - loss: 1.4244 - val_accuracy: 0.6947 - val_loss: 1.1210 - learning_rate: 1.0000e-05\n",
    "Epoch 2/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.7831 - loss: 0.6756\n",
    "Epoch 2: val_accuracy improved from 0.69466 to 0.76463, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.7831 - loss: 0.6755 - val_accuracy: 0.7646 - val_loss: 0.7904 - learning_rate: 1.0000e-05\n",
    "Epoch 3/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.8249 - loss: 0.5242\n",
    "Epoch 3: val_accuracy improved from 0.76463 to 0.80789, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.8249 - loss: 0.5240 - val_accuracy: 0.8079 - val_loss: 0.6306 - learning_rate: 1.0000e-05\n",
    "Epoch 4/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.8527 - loss: 0.4374\n",
    "Epoch 4: val_accuracy improved from 0.80789 to 0.81425, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.8527 - loss: 0.4373 - val_accuracy: 0.8142 - val_loss: 0.5785 - learning_rate: 1.0000e-05\n",
    "Epoch 5/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.8824 - loss: 0.3357\n",
    "Epoch 5: val_accuracy improved from 0.81425 to 0.83206, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.8824 - loss: 0.3357 - val_accuracy: 0.8321 - val_loss: 0.5253 - learning_rate: 1.0000e-05\n",
    "Epoch 6/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.8863 - loss: 0.3275\n",
    "Epoch 6: val_accuracy improved from 0.83206 to 0.83461, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.8863 - loss: 0.3274 - val_accuracy: 0.8346 - val_loss: 0.5096 - learning_rate: 1.0000e-05\n",
    "Epoch 7/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9061 - loss: 0.2869\n",
    "Epoch 7: val_accuracy improved from 0.83461 to 0.83969, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9061 - loss: 0.2869 - val_accuracy: 0.8397 - val_loss: 0.4851 - learning_rate: 1.0000e-05\n",
    "Epoch 8/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9176 - loss: 0.2402\n",
    "Epoch 8: val_accuracy improved from 0.83969 to 0.84987, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9176 - loss: 0.2402 - val_accuracy: 0.8499 - val_loss: 0.4604 - learning_rate: 1.0000e-05\n",
    "Epoch 9/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9299 - loss: 0.2069\n",
    "Epoch 9: val_accuracy improved from 0.84987 to 0.85369, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9299 - loss: 0.2069 - val_accuracy: 0.8537 - val_loss: 0.4388 - learning_rate: 1.0000e-05\n",
    "Epoch 10/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9323 - loss: 0.1973\n",
    "Epoch 10: val_accuracy improved from 0.85369 to 0.85751, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9323 - loss: 0.1973 - val_accuracy: 0.8575 - val_loss: 0.4210 - learning_rate: 1.0000e-05\n",
    "Epoch 11/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9419 - loss: 0.1736\n",
    "Epoch 11: val_accuracy improved from 0.85751 to 0.86387, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9419 - loss: 0.1736 - val_accuracy: 0.8639 - val_loss: 0.4139 - learning_rate: 1.0000e-05\n",
    "Epoch 12/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9429 - loss: 0.1645\n",
    "Epoch 12: val_accuracy improved from 0.86387 to 0.86641, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9429 - loss: 0.1645 - val_accuracy: 0.8664 - val_loss: 0.4085 - learning_rate: 1.0000e-05\n",
    "Epoch 13/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9462 - loss: 0.1517\n",
    "Epoch 13: val_accuracy improved from 0.86641 to 0.87659, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9462 - loss: 0.1516 - val_accuracy: 0.8766 - val_loss: 0.3916 - learning_rate: 1.0000e-05\n",
    "Epoch 14/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9610 - loss: 0.1222\n",
    "Epoch 14: val_accuracy did not improve from 0.87659\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9610 - loss: 0.1222 - val_accuracy: 0.8753 - val_loss: 0.3802 - learning_rate: 1.0000e-05\n",
    "Epoch 15/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9599 - loss: 0.1169\n",
    "Epoch 15: val_accuracy improved from 0.87659 to 0.88295, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9599 - loss: 0.1169 - val_accuracy: 0.8830 - val_loss: 0.3744 - learning_rate: 1.0000e-05\n",
    "Epoch 16/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9628 - loss: 0.1143\n",
    "Epoch 16: val_accuracy did not improve from 0.88295\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9628 - loss: 0.1142 - val_accuracy: 0.8817 - val_loss: 0.3703 - learning_rate: 1.0000e-05\n",
    "Epoch 17/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9689 - loss: 0.0996\n",
    "Epoch 17: val_accuracy did not improve from 0.88295\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9689 - loss: 0.0996 - val_accuracy: 0.8830 - val_loss: 0.3629 - learning_rate: 1.0000e-05\n",
    "Epoch 18/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9686 - loss: 0.0924\n",
    "Epoch 18: val_accuracy did not improve from 0.88295\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9686 - loss: 0.0924 - val_accuracy: 0.8804 - val_loss: 0.3621 - learning_rate: 1.0000e-05\n",
    "Epoch 19/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9761 - loss: 0.0828\n",
    "Epoch 19: val_accuracy did not improve from 0.88295\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9761 - loss: 0.0828 - val_accuracy: 0.8804 - val_loss: 0.3533 - learning_rate: 1.0000e-05\n",
    "Epoch 20/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9740 - loss: 0.0815\n",
    "Epoch 20: val_accuracy improved from 0.88295 to 0.88931, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9740 - loss: 0.0815 - val_accuracy: 0.8893 - val_loss: 0.3463 - learning_rate: 1.0000e-05\n",
    "Epoch 21/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9762 - loss: 0.0690\n",
    "Epoch 21: val_accuracy improved from 0.88931 to 0.89186, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9762 - loss: 0.0690 - val_accuracy: 0.8919 - val_loss: 0.3453 - learning_rate: 1.0000e-05\n",
    "Epoch 22/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9834 - loss: 0.0561\n",
    "Epoch 22: val_accuracy improved from 0.89186 to 0.89313, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9834 - loss: 0.0561 - val_accuracy: 0.8931 - val_loss: 0.3350 - learning_rate: 1.0000e-05\n",
    "Epoch 23/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9828 - loss: 0.0621\n",
    "Epoch 23: val_accuracy did not improve from 0.89313\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9828 - loss: 0.0621 - val_accuracy: 0.8931 - val_loss: 0.3334 - learning_rate: 1.0000e-05\n",
    "Epoch 24/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9836 - loss: 0.0616\n",
    "Epoch 24: val_accuracy did not improve from 0.89313\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9836 - loss: 0.0616 - val_accuracy: 0.8919 - val_loss: 0.3293 - learning_rate: 1.0000e-05\n",
    "Epoch 25/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9856 - loss: 0.0524\n",
    "Epoch 25: val_accuracy improved from 0.89313 to 0.89440, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9855 - loss: 0.0525 - val_accuracy: 0.8944 - val_loss: 0.3289 - learning_rate: 1.0000e-05\n",
    "Epoch 26/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9864 - loss: 0.0505\n",
    "Epoch 26: val_accuracy did not improve from 0.89440\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9864 - loss: 0.0505 - val_accuracy: 0.8944 - val_loss: 0.3250 - learning_rate: 1.0000e-05\n",
    "Epoch 27/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9872 - loss: 0.0452\n",
    "Epoch 27: val_accuracy did not improve from 0.89440\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9872 - loss: 0.0452 - val_accuracy: 0.8931 - val_loss: 0.3246 - learning_rate: 1.0000e-05\n",
    "Epoch 28/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9927 - loss: 0.0401\n",
    "Epoch 28: val_accuracy improved from 0.89440 to 0.90331, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9927 - loss: 0.0401 - val_accuracy: 0.9033 - val_loss: 0.3167 - learning_rate: 1.0000e-05\n",
    "Epoch 29/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9874 - loss: 0.0397\n",
    "Epoch 29: val_accuracy did not improve from 0.90331\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 44ms/step - accuracy: 0.9874 - loss: 0.0397 - val_accuracy: 0.9008 - val_loss: 0.3179 - learning_rate: 1.0000e-05\n",
    "Epoch 30/30\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.9865 - loss: 0.0447\n",
    "Epoch 30: val_accuracy improved from 0.90331 to 0.90458, saving model to /kaggle/working/best_finetuned.h5\n",
    "197/197 ━━━━━━━━━━━━━━━━━━━━ 9s 45ms/step - accuracy: 0.9865 - loss: 0.0446 - val_accuracy: 0.9046 - val_loss: 0.3128 - learning_rate: 1.0000e-05\n",
    "Restoring model weights from the end of the best epoch: 30.\n",
    "Saved model to: /kaggle/working/mobilenet_finetuned.h5\n",
    "25/25 ━━━━━━━━━━━━━━━━━━━━ 1s 27ms/step - accuracy: 0.8846 - loss: 0.3854\n",
    "Test loss: 0.3207  Test accuracy: 0.8982\n",
    "25/25 ━━━━━━━━━━━━━━━━━━━━ 4s 105ms/step\n",
    "\n",
    "Classification report (per-class):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9000    1.0000    0.9474        27\n",
    "           1     0.8571    1.0000    0.9231        18\n",
    "           2     1.0000    1.0000    1.0000        29\n",
    "           3     0.8378    0.9394    0.8857        33\n",
    "           4     0.9231    0.8889    0.9057        27\n",
    "           5     0.7200    0.9000    0.8000        20\n",
    "           6     0.8571    0.9000    0.8780        20\n",
    "           7     0.9524    1.0000    0.9756        20\n",
    "           8     0.9333    0.7778    0.8485        18\n",
    "           9     0.8519    0.9583    0.9020        24\n",
    "          10     0.9565    0.9167    0.9362        24\n",
    "          11     0.8788    0.9355    0.9062        31\n",
    "          12     0.9615    0.8929    0.9259        28\n",
    "          13     0.8800    0.9565    0.9167        23\n",
    "          14     1.0000    0.7407    0.8511        27\n",
    "          15     0.8636    0.7600    0.8085        25\n",
    "          16     0.9118    0.9118    0.9118        34\n",
    "          17     0.9412    0.7273    0.8205        22\n",
    "          18     0.9444    0.7727    0.8500        22\n",
    "          19     0.9032    0.9333    0.9180        30\n",
    "          20     0.9500    0.9500    0.9500        20\n",
    "          21     1.0000    0.9697    0.9846        33\n",
    "          22     0.8824    0.8824    0.8824        17\n",
    "          23     0.9231    0.8571    0.8889        42\n",
    "          24     0.9545    0.9545    0.9545        22\n",
    "          25     0.6538    0.8947    0.7556        19\n",
    "          26     0.8519    0.7931    0.8214        29\n",
    "          27     1.0000    1.0000    1.0000        24\n",
    "          28     0.8000    0.9333    0.8615        30\n",
    "          29     0.8696    0.9091    0.8889        22\n",
    "          30     1.0000    0.7692    0.8696        26\n",
    "\n",
    "    accuracy                         0.8982       786\n",
    "   macro avg     0.9019    0.8976    0.8957       786\n",
    "weighted avg     0.9055    0.8982    0.8981       786\n",
    "\n",
    "Confusion matrix shape: (31, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T23:46:46.817757Z",
     "iopub.status.busy": "2025-08-22T23:46:46.817081Z",
     "iopub.status.idle": "2025-08-22T23:46:47.036260Z",
     "shell.execute_reply": "2025-08-22T23:46:47.035502Z",
     "shell.execute_reply.started": "2025-08-22T23:46:46.817733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/mobilenet_finetuned.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2852448,
     "sourceId": 6116155,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
